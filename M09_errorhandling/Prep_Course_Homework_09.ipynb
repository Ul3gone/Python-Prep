{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de errores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Con la clase creada en el módulo 7, tener en cuenta diferentes casos en que el código pudiera arrojar error. Por ejemplo, en la creación del objeto recibimos una lista de números enteros pero ¿qué pasa si se envía otro tipo de dato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modulo_herramientas as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "El valor ingresado no es una lista",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTools\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHola\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m h1\u001b[38;5;241m.\u001b[39mfactorial()\n",
      "File \u001b[1;32mc:\\Users\\ulise\\Desktop\\Python-Prep\\M09_errorhandling\\modulo_herramientas.py:5\u001b[0m, in \u001b[0;36mTools.__init__\u001b[1;34m(self, lista_mumeros)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(lista_mumeros) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEl valor ingresado no es una lista\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m lista_mumeros\n",
      "\u001b[1;31mValueError\u001b[0m: El valor ingresado no es una lista"
     ]
    }
   ],
   "source": [
    "h1 = h.Tools('Hola')\n",
    "\n",
    "h1.factorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = h.Tools([1,2,3,4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) En la función que hace la conversión de grados, validar que los parámetros enviados sean los esperados, de no serlo, informar cuáles son los valores esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modulo_herramientas' from 'c:\\\\Users\\\\ulise\\\\Desktop\\\\Python-Prep\\\\M09_errorhandling\\\\modulo_herramientas.py'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de origen debe ser una de estas opciones:  ['celsius', 'farenheit', 'kelvin']\n"
     ]
    }
   ],
   "source": [
    "h2 = h.Tools([1,2,3,4])\n",
    "h2.conversion_grados(2,'celsius')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Importar el modulo \"unittest\" y crear los siguientes casos de pruebas sobre la clase utilizada en el punto 2<br>\n",
    "Creacion del objeto incorrecta<br>\n",
    "Creacion correcta del objeto<br>\n",
    "Metodo valor_modal()<br>\n",
    "\n",
    "Se puede usar \"raise ValueError()\" en la creación de la clase para verificar el error. Investigar sobre esta funcionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class Probar_codigo(unittest.TestCase):\n",
    "\n",
    "    def test_creacion_objeto_1(self):\n",
    "        param = [1,2,3,4]\n",
    "        h1 = h.Tools(param)\n",
    "        self.assertEqual(h1.lista, param)\n",
    "\n",
    "    def test_creacion_objeto_2(self):\n",
    "        param = 'hola'\n",
    "        self.assertRaises(ValueError, h.Tools, param)\n",
    "\n",
    "    def test_valor_modal(self):\n",
    "        lis = [1,2,3,4,4]\n",
    "        h1 = h.Tools(lis)\n",
    "        moda, repeticiones = h1.valor_modal()\n",
    "        resultados = [moda]\n",
    "        resultados.append(repeticiones)\n",
    "        resultados_esperados = [4,2]\n",
    "        self.assertEqual(resultados, resultados_esperados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_creacion_objeto_1 (__main__.Probar_codigo.test_creacion_objeto_1) ... ok\n",
      "test_creacion_objeto_2 (__main__.Probar_codigo.test_creacion_objeto_2) ... ok\n",
      "test_valor_modal (__main__.Probar_codigo.test_valor_modal) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x26c837f0290>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Probar una creación incorrecta y visualizar la salida del \"raise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "El valor ingresado no es una lista",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h2 \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTools\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhola\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ulise\\Desktop\\Python-Prep\\M09_errorhandling\\modulo_herramientas.py:5\u001b[0m, in \u001b[0;36mTools.__init__\u001b[1;34m(self, lista_mumeros)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(lista_mumeros) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEl valor ingresado no es una lista\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m lista_mumeros\n",
      "\u001b[1;31mValueError\u001b[0m: El valor ingresado no es una lista"
     ]
    }
   ],
   "source": [
    "h2 = h.Tools('hola')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Agregar casos de pruebas para el método verifica_primos() realizando el cambio en la clase, para que devuelva una lista de True o False en función de que el elemento en la posisicón sea o no primo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modulo_herramientas' from 'c:\\\\Users\\\\ulise\\\\Desktop\\\\Python-Prep\\\\M09_errorhandling\\\\modulo_herramientas.py'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probando_mprimos(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_primo(self):\n",
    "        lista = [2,3,4,5]\n",
    "        h1 = h.Tools(lista)\n",
    "        resultado = h1.verifica_primo()\n",
    "        resultado_esperado = [True,True,False,True]\n",
    "        self.assertEqual(resultado,resultado_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modulo_herramientas' from 'c:\\\\Users\\\\ulise\\\\Desktop\\\\Python-Prep\\\\M09_errorhandling\\\\modulo_herramientas.py'>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_verifica_primo (__main__.Probando_mprimos.test_verifica_primo) ... ok\n",
      "test_creacion_objeto_1 (__main__.Probar_codigo.test_creacion_objeto_1) ... ok\n",
      "test_creacion_objeto_2 (__main__.Probar_codigo.test_creacion_objeto_2) ... ok\n",
      "test_valor_modal (__main__.Probar_codigo.test_valor_modal) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x26c83787f50>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Agregar casos de pruebas para el método conversion_grados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modulo_herramientas' from 'c:\\\\Users\\\\ulise\\\\Desktop\\\\Python-Prep\\\\M09_errorhandling\\\\modulo_herramientas.py'>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probando_conversion(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_conversion(self):\n",
    "        lista = [2,1,1,4,8,8,8]\n",
    "        h1 = h.Tools(lista)\n",
    "        resultado = h1.conversion_grados('celsius','kelvin')\n",
    "        resltado_esperado = [275.15,274.15,274.15,277.15,281.15,281.15,281.15]\n",
    "        self.assertEqual(resultado,resltado_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_verifica_conversion (__main__.Probando_conversion.test_verifica_conversion) ... ok\n",
      "test_verifica_primo (__main__.Probando_mprimos.test_verifica_primo) ... ok\n",
      "test_creacion_objeto_1 (__main__.Probar_codigo.test_creacion_objeto_1) ... ok\n",
      "test_creacion_objeto_2 (__main__.Probar_codigo.test_creacion_objeto_2) ... ok\n",
      "test_valor_modal (__main__.Probar_codigo.test_valor_modal) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.005s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x26c83806490>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Agregar casos de pruebas para el método factorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modulo_herramientas' from 'c:\\\\Users\\\\ulise\\\\Desktop\\\\Python-Prep\\\\M09_errorhandling\\\\modulo_herramientas.py'>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probando_metodo_factorial(unittest.TestCase):\n",
    "\n",
    "    def test_verificar_factorial(self):\n",
    "        lista = [1,5,8,2,2,2]\n",
    "        h1 = h.Tools(lista)\n",
    "        resultado = h1.factorial()\n",
    "        resultado_esperado = [1,120,40320,2,2,2]\n",
    "        self.assertEqual(resultado,resultado_esperado)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_verifica_conversion (__main__.Probando_conversion.test_verifica_conversion) ... ok\n",
      "test_verificar_factorial (__main__.Probando_metodo_factorial.test_verificar_factorial) ... ok\n",
      "test_verifica_primo (__main__.Probando_mprimos.test_verifica_primo) ... ok\n",
      "test_creacion_objeto_1 (__main__.Probar_codigo.test_creacion_objeto_1) ... ok\n",
      "test_creacion_objeto_2 (__main__.Probar_codigo.test_creacion_objeto_2) ... ok\n",
      "test_valor_modal (__main__.Probar_codigo.test_valor_modal) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.010s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x26c8350a850>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c85384e4cb51c8b72350f3a8712cc8351fdc3955e32a27f9b60c6242ab125f01"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
